import pathlib
import threading
import time
import warnings
from contextlib import contextmanager
from typing import Optional, Tuple

import av
import numpy as np
from numpy.typing import NDArray


def extract_keyframe_times_and_points(
    video_path: str | pathlib.Path, stream_index: int = 0, first_only=False
) -> Tuple[NDArray, NDArray]:
    """
    Extract the indices and timestamps of keyframes from a video file.

    This function decodes the video while skipping non-keyframes, and records:
    - The index of each keyframe in the full video frame sequence
    - The "Presentation Time Stamp" to each keyframe.

    It is typically intended to run in a background thread during
    initialization of a ``VideoHandler``, and supports optimized seeking:

    - When the requested frame (based on experimental time) is before the
      current playback position, seeking backward is necessary.

    - When the requested frame is beyond the next known keyframe, seeking
      forward to the closest keyframe is more efficient than decoding all
      intermediate frames.

    Parameters
    ----------
    video_path : str or pathlib.Path
        The path to the video file.
    stream_index:
        The index of the video stream.
    first_only:
        If true, return the first keypoint only. Used at initialization.

    Returns
    -------
    keyframe_points : NDArray[float]
        The point number of the frame.

    keyframe_timestamps : NDArray[float]
        The timestamp of the frame.
    """
    keyframe_timestamp = []
    keyframe_pts = []

    with av.open(video_path) as container:
        stream = container.streams.video[stream_index]
        stream.codec_context.skip_frame = "NONKEY"

        frame_index = 0
        for frame in container.decode(stream):
            keyframe_timestamp.append(frame.time)
            keyframe_pts.append(frame.pts)
            if first_only:
                break
            frame_index += 1

    return np.asarray(keyframe_pts), np.asarray(keyframe_timestamp, dtype=float)


def ts_to_index(ts: float, time: NDArray) -> int:
    """
    Return the index of the frame whose experimental time is just before (or equal to) `ts`.

    Parameters
    ----------
    ts : float
        Experimental timestamp to match.
    time : NDArray
        Array of experimental timestamps, assumed sorted in ascending order,
        with one entry per frame.

    Returns
    -------
    idx : int
        Index of the frame with time <= `ts`. Clipped to [0, len(time) - 1].

    Notes
    -----
    - If `ts` is smaller than all values in `time`, returns 0.
    - If `ts` is greater than all values in `time`, returns `len(time) - 1`.
    """
    idx = np.searchsorted(time, ts, side="right") - 1
    return np.clip(idx, 0, len(time) - 1)


def extract_keyframe_pts(video_path: str | pathlib.Path) -> NDArray:
    """Extract keyframe presentation time without decoding."""
    with av.open(video_path) as container:
        stream = container.streams.video[0]
        keyframe_pts = [
            packet.pts for packet in container.demux(stream) if packet.is_keyframe
        ]
    return np.array(keyframe_pts, int)


class VideoHandler:
    """Class for getting video frames."""

    _get_from_index = False

    def __init__(
        self,
        video_path: str | pathlib.Path,
        stream_index=0,
        time: Optional[NDArray] = None,
        return_frame_array=True,
    ) -> None:
        self.video_path = pathlib.Path(video_path)
        self.container = av.open(video_path)
        self.stream = self.container.streams.video[stream_index]
        self.stream_index = stream_index
        self.return_frame_array = return_frame_array
        self._running = True

        # default to linspace
        if time is None:
            self._time_provided = False
            n_frames = self.stream.frames
            frame_duration = 1 / float(self.stream.average_rate)
            self.time = np.linspace(
                0, frame_duration * n_frames - frame_duration, n_frames
            )
        else:
            self._time_provided = True
            self.time = np.asarray(time)

        # initialize decoded frame last index
        # if sampling of other signals (LFP) is much denser, multiple times the frame
        # is unchanged, so cache the idx
        self.last_idx = None

        # initialize current frame
        self.current_frame: Optional[av.VideoFrame] = None

        if self.video_path.suffix == ".mkv":
            # mkv time is rounded to 3 digits, at least in the example video
            # generated by tests/generate_numbered_video.py
            self.round_fn = lambda x: np.round(x, 3)
        else:
            self.round_fn = lambda x: x

        # These will be initialized in the thread once n_frames is known
        self.all_pts = None
        self.all_times = None
        self.key_mask = None

        self._i = 0  # write position
        self._lock = threading.Lock()
        if self.stream.frames and self.stream.frames > 0:
            self._index_thread = threading.Thread(
                target=self._build_index_fixed_size, daemon=True
            )
        else:
            self._index_thread = threading.Thread(
                target=self._build_index_dynamic, daemon=True
            )

        self._index_thread.start()
        self._index_ready = threading.Event()
        self._pts_keypoint_ready = threading.Event()
        self._keypoint_thread = threading.Thread(
            target=lambda: self._extract_keypoints_pts(video_path), daemon=True
        )
        self._keypoint_thread.start()

    @contextmanager
    def _set_get_from_index(self, value):
        """Context manager for setting the shallow copy flag in a thread safe way."""
        old_value = self.__class__._get_from_index
        self.__class__._get_from_index = value
        try:
            yield
        finally:
            self.__class__._get_from_index = old_value

    def _extract_keypoints_pts(self, video_path: str | pathlib.Path):
        self._keypoint_pts = extract_keyframe_pts(video_path)
        self._pts_keypoint_ready.set()

    def _build_index_fixed_size(self):
        with av.open(self.video_path) as container:
            stream = container.streams.video[self.stream_index]
            n_frames = stream.frames

            if not n_frames or n_frames <= 0:
                raise ValueError("Cannot determine total number of frames in stream.")

            self.all_pts = np.empty(n_frames, dtype=np.int64)
            self._i = 0  # Number of valid entries

            for packet in container.demux(stream):
                for frame in packet.decode():
                    if self._i >= n_frames:
                        break
                    with self._lock:
                        self.all_pts[self._i] = frame.pts
                        self._i += 1

            self._index_ready.set()

    def _build_index_dynamic(self):
        with av.open(self.video_path) as container:
            stream = container.streams.video[self.stream_index]
            pts_list = []

            current_index = 0
            flush_every = 10  # number of frames over which flushing to all points
            for packet in container.demux(stream):
                for frame in packet.decode():
                    if frame.pts is not None:
                        pts_list.append(frame.pts)
                        if current_index % flush_every == 1:
                            with self._lock:
                                self.all_pts = pts_list
                                self._i = current_index
                        current_index += 1

            self._index_ready.set()

    def _need_seek_call(self, current_frame_pts, target_frame_pts):
        if not self._pts_keypoint_ready.is_set() or len(self._keypoint_pts) == 0:
            return True

        # roll back the stream if video is scrolled backwards
        if current_frame_pts > target_frame_pts:
            return True

        # find the closest keypoint pts before a given frame
        idx = np.searchsorted(self._keypoint_pts, target_frame_pts, side="right")
        closest_keypoint_pts = self._keypoint_pts[max(0, idx - 1)]

        # if target_frame_pts is larger than current (and if code
        # arrives here, it is, see second return statement),
        # then seek forward if there is a future keypoint closest
        # to the target.
        return closest_keypoint_pts > current_frame_pts

    def _get_target_frame_pts(self, idx: int):
        """
        Get the target frame presentation time stamp from frame index.

        Parameters
        ----------
        idx:
            The frame index.

        Returns
        -------
        target_pts:
            The target frame presentation time stamp corresponding to the frame index.
        use_time:
            If true, search using presentation time in seconds, otherwise use pts.

        """
        # Wait until enough index is available
        # Estimate pts from index (using filled index if available)
        if self._i > idx:
            # the pts for this timestamp has been filled
            with self._lock:
                target_pts = self.all_pts[idx]
            use_time = False
        else:
            # keep going until at least two frames have been decoded by the thread
            while True:
                with self._lock:
                    if self._i > 1:
                        break
                time.sleep(0.001)
            # use recent history to get the step estimate
            with self._lock:
                # Linear extrapolation from available pts (use last 10 steps for an estimate)
                start, stop = max(self._i - 10, 0), self._i
                avg_step = np.mean(np.diff(self.all_pts[start:stop]))
                target_pts = int(self.all_pts[0] + avg_step * idx)
                use_time = True
        return target_pts, use_time

    def get(self, ts: float) -> av.VideoFrame:

        if not self.__class__._get_from_index:
            idx = ts_to_index(ts, self.time)
        else:
            idx = ts

        if idx == self.last_idx:
            return (
                self.current_frame.to_ndarray(format="rgb24")[::-1] / 255.0
                if self.return_frame_array
                else self.current_frame
            )

        target_pts, use_time = self._get_target_frame_pts(idx)

        if not hasattr(self.current_frame, "pts") or self._need_seek_call(
            self.current_frame.pts, target_pts
        ):
            self.container.seek(
                int(target_pts), backward=True, any_frame=False, stream=self.stream
            )

        # Decode forward from the keypoint until the frame just before (or equal to) target_pts
        last_idx, preceding_frame = self._decode_and_check_frames(
            use_time, target_pts, idx
        )

        if preceding_frame is not None:
            self.last_idx = idx
            self.current_frame = preceding_frame

        return (
            self.current_frame.to_ndarray(format="rgb24")[::-1] / 255.0
            if self.return_frame_array
            else self.current_frame
        )

    def _decode_and_check_frames(self, use_time: bool, target_pts: int, idx: int):
        """Decode from stream."""
        preceding_frame = None
        last_idx = self.last_idx
        frame_duration = 1 / float(self.stream.average_rate)
        time_threshold = self.round_fn(idx * frame_duration)

        for packet in self.container.demux(self.stream):
            if packet is None:
                continue
            for frame in packet.decode():
                if frame.pts is None:
                    continue
                if (not use_time and frame.pts > target_pts) or (
                    use_time and frame.time > time_threshold
                ):
                    last_idx = idx
                    current_frame = preceding_frame or frame
                    return last_idx, current_frame
                elif (not use_time and frame.pts == target_pts) or (
                    use_time and frame.time == time_threshold
                ):
                    last_idx = idx
                    current_frame = frame
                    return last_idx, current_frame
                preceding_frame = frame
        return last_idx, preceding_frame

    @property
    def shape(self):
        if self._time_provided:
            return len(self.time), self.stream.width, self.stream.height
        has_frames = hasattr(self.stream, "frames") and self.stream.frames > 0
        is_done_unpacking = self._index_ready.is_set()
        if not has_frames and not is_done_unpacking:
            warnings.warn(
                message="Video ``shape``, which corresponds to the number of frames, is being "
                "calculated runtime and will be updated.",
                stacklevel=2,
            )
        return (
            (len(self.time), self.stream.width, self.stream.height)
            if has_frames
            else (len(self.all_pts), self.stream.width, self.stream.height)
        )

    @property
    def index(self):
        if self._time_provided:
            return self.time
        else:
            has_frames = hasattr(self.stream, "frames") and self.stream.frames > 0
            is_done_unpacking = self._index_ready.is_set()
            if not has_frames and not is_done_unpacking:
                warnings.warn(
                    message="Video ``shape``, which corresponds to the number of frames, is being "
                    "calculated runtime and will be updated.",
                    stacklevel=2,
                )
            return self.time

    @property
    def t(self):
        return self.time

    def close(self):
        """Close the video stream."""
        self._running = False
        if self._index_thread.is_alive():
            self._index_thread.join(timeout=1)  # Be conservative, donâ€™t block forever
        try:
            self.container.close()
        except Exception:
            pass

    def wait_for_index(self, timeout=2.0):
        """Wait up to timeout.

        For debugging purposes, or testing, make sure that the
        threads are completed.
        """
        self._index_ready.wait(timeout)
        self._pts_keypoint_ready.wait(timeout)

    def get_slice(self, ts: float):
        idx = ts_to_index(ts, self.time)
        return slice(idx, idx + 1)

    def _decode_multiple(self, target_pts, idx_start: int, idx_end: int, step: int = 1,  use_time: bool=False):
        """Decode frames from idx_start to idx_end (exclusive) with optional step.

        Starts at the first frame that satisfies the time/PTS condition,
        then collects every `step`-th frame afterward.
        """
        frame_duration = 1 / float(self.stream.average_rate)
        effective_end = min(idx_end, self.shape[0])
        indices = np.arange(idx_start, effective_end, step)
        num_frames = len(indices)

        # Threshold for the first frame
        time_threshold = self.round_fn(indices[0] * frame_duration)

        # initialize frame container
        if self.return_frame_array:
            frames = np.empty((num_frames, self.shape[2], self.shape[1], 3), dtype=np.float32)
        else:
            frames = []
        collecting = False
        preceding_frame = None
        step_counter = 0  # Counts decoded frames after starting

        for packet in self.container.demux(self.stream):
            if packet is None:
                continue
            for frame in packet.decode():
                if frame.pts is None:
                    continue

                if not collecting:
                    # Wait until the first frame that meets the threshold
                    condition = (frame.pts >= target_pts) if not use_time else (frame.time >= time_threshold)
                    if condition:
                        if self.return_frame_array:
                            frames[step_counter] = frame.to_ndarray(format="rgb24")[::-1] / 255.0
                        else:
                            frames.append(preceding_frame or frame)
                        collecting = True
                        step_counter = 1  # we just got the first frame
                else:
                    if step_counter % step == 0:
                        if self.return_frame_array:
                            frames[step_counter // step] = frame.to_ndarray(format="rgb24")[::-1] / 255.0
                        else:
                            frames.append(preceding_frame or frame)
                    step_counter += 1

                    if len(frames) == num_frames:
                        return indices[0] + len(frames) * step, frames

                preceding_frame = frame

        return indices[0] + len(frames) * step, frames

    def __getitem__(self, idx: slice | int):
        """
        Get item for video frame.

        Get a single frame from the video, if a `slice` is provided, it gets
         `slice.start`.

        Parameters
        ----------
        idx:
            The index for slicing.

        Returns
        -------
        frame:
            A video frame.

        """
        if isinstance(idx, slice):
            # Fill in missing slice components
            start = idx.start or 0
            stop = idx.stop if idx.stop is not None else self.shape[0]
            step = idx.step if idx.step is not None else 1
            idx = slice(start, stop, step)

            if (idx.stop - idx.start) // idx.step > 1:
                target_pts, use_time = self._get_target_frame_pts(idx.start)

                if not hasattr(self.current_frame, "pts") or self._need_seek_call(
                        self.current_frame.pts, target_pts
                ):
                    self.container.seek(
                        int(target_pts), backward=True, any_frame=False, stream=self.stream
                    )

                frame_idx, frames = self._decode_multiple(
                    target_pts, idx.start, idx.stop, use_time=use_time, step=idx.step
                )
                # update current decoded frame
                if len(frames):
                    self.last_idx = frame_idx
                    self.current_frame = frames[-1]
                return frames
            else:
                idx = idx.start  # fallback to single-index logic

        # Default case: single index
        with self._set_get_from_index(True):
            frame = self.get(idx)

        return frame
